---
title: "Machone Learning using Caret"
output: html_notebook
author: Jeff Gross
---

Packages/Misc
```{r}
options(tibble.print_max = Inf)
options(tibble.width = Inf)

#get a def of a function
getAnywhere(draw_roc_lines)

install.packages("caret")
library(caret)

data(Sonar)
install.packages("e1071")
library(e1071)
install.packages("caTools")
library(caTools)
install.packages("ranger")
library(ranger)
installed.packages("RANN")
library(RANN)
installed.packages("glmnet")
library(glmnet)
installed.packages("Matrix")
library(Matrix)
installed.packages("foreach")
library(foreach)
installed.packages("caretEnsemble")
library(caretEnsemble)

```


##10-fold cross-validation
```{r}
diamonds <- read_csv("~/R Scripts/diamonds.csv")

# Fit lm model using 10-fold CV: model
#  class_prediction <-
#  ifelse(probability_prediction > 0.50,
#         "positive_class",
#         "negative_class"
#  )

model <- train(
  price ~ ., diamonds,
  method = "lm",
  trControl = trainControl(
    method = "cv", number = 10,
    verboseIter = TRUE
  )
)

# Print model to console
print(model)
```

##10*5-fold cross-validation
```{r}
# Fit lm model using 10-fold CV: model:
#  class_prediction <-
#  ifelse(probability_prediction > 0.50,
#         "positive_class",
#         "negative_class"
#  )

model1 <- train(
  price ~ ., diamonds,
  method = "lm",
  trControl = trainControl(
    method = "cv", number = 10,
    repeats=5, verboseIter = TRUE
  )
)

# Print model to console
print(model1)
```

##Making predictions on new data
```{r}
# Predict on full Boston dataset
predict(model1, diamonds)
```

##Another data set: 60/40 split, logistic
```{r}
# Shuffle row indices: rows : rows <- sample(nrow(my_data))
rows <- sample(nrow(Sonar))

# Randomly order data: Sonar: my_data <- my_data[rows, ]
Sonar <- Sonar[rows,]

# Identify row to split on: split
split <- round(nrow(Sonar) * .60)

# Create train
train <- Sonar[1:split,]

# Create test
test <- Sonar[(split + 1):nrow(Sonar),]

# Fit glm model: model: glm(Target ~ ., family = "binomial", dataset)
model <- glm(Class ~ ., family = "binomial", train)

# Predict on test: p: predict(my_model, test, type = "response")
p <- predict(model, test, type = "response")


```
Don't worry about warnings like glm.fit: algorithm did not converge or glm.fit: fitted probabilities numerically 0 or 1 occurred. These are common on smaller datasets and usually don't cause any issues. They typically mean your dataset is perfectly seperable, which can cause problems for the math behind the model, but R's glm() function is almost always robust enough to handle this case with no problems.

##Calculate a confusion matrix
```{r}
# Calculate class probabilities: p_class :pred <- ifelse(probability > threshold, "M", "R")
p_class <-
  ifelse(p > 0.50,
         "M",
         "R"
  )

# Create confusion matrix: confusionMatrix(pred, actual)
confusionMatrix(p_class, test$Class)
```
Make sure to use "M" for the positive class and "R" for the negative class when making predictions, to match the classes in the original data.

##Try another threshold: .9
```{r}
# Apply threshold of 0.9: p_class :pred <- ifelse(probability > threshold, "M", "R")
p_class <- ifelse(p > .9, "M", "R")

# Create confusion matrix: confusionMatrix(pred, actual)
confusionMatrix(p_class, test$Class)
```
Amazing! Note that there are (slightly) fewer predicted mines with this higher threshold: 45 (40 + 15) as compared to 47 for the 0.50 threshold.

##Plot an ROC curve
```{r}
# Predict on test: p
p <- predict(model, test, type = "response")

# Make ROC curve: colAUC(predicted_probabilities, actual, plotROC = TRUE)
colAUC(p, test$Class, plotROC = TRUE)
```

##ROC/AuC
```{r}
# Create trainControl object: myControl
myControl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = TRUE
)

# Train glm with custom trainControl: model
model <- train(method="glm", Class ~ ., data=Sonar, trControl = myControl)


# Print model to console
print(model)
```
For now, don't worry about the warning messages generated by your code.

##Fit a random forest
```{r}
wine <- read_csv("~/R Scripts/wine.csv")
rownames(wine) <- wine$X1
wine$X1 <- NULL
View(wine)

# Fit random forest: model
model <- train(
  quality ~ .,
  tuneLength = 1,
  data = wine, method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

# Print model to console
print(model)
```

##Try a longer tune length:
Random forest models have a primary tuning parameter of mtry, which controls how many variables are exposed to the splitting search routine at each split. For example, suppose that a tree has a total of 10 splits and mtry = 2. This means that there are 10 samples of 2 predictors each time a split is evaluated.
```{r}
# Fit random forest: model
model <- train(
  quality ~ .,
  tuneLength = 3,
  data = wine, method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

# Print model to console
print(model)

# Plot model
plot(model)
```

##Fit a random forest with custom tuning
```{r}
# Fit random forest: model
model <- train(
  quality ~ .,
  tuneGrid = data.frame(mtry = c(2, 3, 7)),
  data = wine, method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

# Print model to console
print(model)

# Plot model
plot(model)
```

##Make a custom trainControl
```{r}
# Create custom trainControl: myControl
myControl <- trainControl(
  method = "cv", number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = TRUE
)
```

##glmnet
glmnet is an extention of the generalized linear regression model (or glm) that places constraints on the magnitude of the coefficients to prevent overfitting. This is more commonly known as "penalized" regression modeling and is a very useful technique on datasets with many predictors and few values.

glmnet is capable of fitting two different kinds of penalized models, controlled by the alpha parameter:

Ridge regression (or alpha = 0)
Lasso regression (or alpha = 1)
```{r}
overfit <- read_csv("~/R Scripts/overfit.csv")

# Fit glmnet model: model
model <- train(
  y ~ ., overfit,
  method = "glmnet",
  trControl = myControl
)

# Print model to console
print(model)

# Print maximum ROC statistic
max(model[["results"]][["ROC"]])
```

##glmnet with custom trainControl and tuning
```{r}
# Train glmnet with custom trainControl and tuning: model
model <- train(
  y ~ ., overfit,
  tuneGrid = expand.grid(
    alpha = 0:1,
    lambda = seq(.0001, 1, length=100)),
  method = "glmnet",
  trControl = myControl
)

# Print model to console
print(model)

# Print maximum ROC statistic
print(max(model[["results"]][["ROC"]]))

```

##Apply median imputation
```{r}
breast_cancer_y = c("benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",
"malignant",	"malignant",	"benign",	"benign",	"malignant",	"benign",	"malignant",
"malignant",	"benign",	"malignant",	"benign",	"malignant",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",
"benign",	"malignant",	"benign",	"malignant",	"malignant",	"benign",	"malignant",
"malignant",	"malignant",	"malignant",	"benign",	"malignant",	"benign",	"benign",
"malignant",	"malignant",	"malignant",	"malignant",	"malignant",	"malignant",	"malignant",
"malignant",	"malignant",	"malignant",	"malignant",	"malignant",	"benign",	"malignant",
"malignant",	"benign",	"malignant",	"benign",	"malignant",	"malignant",	"benign",
"benign",	"malignant",	"benign",	"malignant",	"malignant",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"malignant",	"malignant",	"malignant",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"malignant",	"malignant",	"malignant",	"malignant",	"benign",	"malignant",	"malignant",
"malignant",	"malignant",	"malignant",	"benign",	"malignant",	"benign",	"malignant",
"malignant",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"benign",
"benign",	"benign",	"benign",	"malignant",	"malignant",	"malignant",	"benign",
"malignant",	"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",
"benign",	"benign",	"malignant",	"benign",	"malignant",	"malignant",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"malignant",
"malignant",	"benign",	"malignant",	"benign",	"malignant",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"benign",	"malignant",	"malignant",	"malignant",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"malignant",	"malignant",	"benign",
"benign",	"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",
"malignant",	"malignant",	"benign",	"malignant",	"malignant",	"malignant",	"benign",
"benign",	"malignant",	"benign",	"benign",	"malignant",	"malignant",	"malignant",
"malignant",	"benign",	"malignant",	"malignant",	"benign",	"malignant",	"malignant",
"malignant",	"benign",	"malignant",	"benign",	"benign",	"malignant",	"malignant",
"malignant",	"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",	"malignant",
"benign",	"malignant",	"malignant",	"malignant",	"benign",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"malignant",	"malignant",	"malignant",	"benign",
"malignant",	"malignant",	"malignant",	"benign",	"malignant",	"benign",	"malignant",
"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",
"benign",	"benign",	"malignant",	"malignant",	"malignant",	"malignant",	"malignant",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"malignant",	"malignant",
"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"malignant",
"benign",	"malignant",	"benign",	"malignant",	"malignant",	"benign",	"benign",
"malignant",	"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"malignant",	"benign",
"benign",	"malignant",	"benign",	"benign",	"malignant",	"benign",	"malignant",
"malignant",	"malignant",	"benign",	"benign",	"malignant",	"malignant",	"benign",
"malignant",	"benign",	"benign",	"malignant",	"malignant",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"malignant",
"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",	"malignant",
"malignant",	"malignant",	"malignant",	"malignant",	"malignant",	"benign",	"benign",
"benign",	"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"benign",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",
"benign",	"malignant",	"benign",	"malignant",	"benign",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"benign",
"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"benign",
"malignant",	"malignant",	"malignant",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"malignant",	"malignant",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",	"malignant",
"malignant",	"benign",	"benign",	"benign",	"malignant",	"malignant",	"malignant",
"benign",	"malignant",	"benign",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"malignant",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"malignant",	"benign",	"benign",
"benign",	"malignant",	"benign",	"benign",	"malignant",	"malignant",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"malignant",	"benign",	"benign",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",
"benign",	"malignant",	"malignant",	"malignant",	"malignant",	"benign",	"benign",
"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"malignant",	"malignant",	"benign",	"benign",	"benign",	"malignant",	"benign",
"malignant",	"benign",	"malignant",	"malignant",	"malignant",	"benign",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"malignant",	"benign",	"benign",	"malignant",
"benign",	"malignant",	"malignant",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",	"malignant",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"malignant",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"malignant",	"malignant",	"malignant",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"benign",	"benign",
"benign",	"malignant",	"malignant",	"benign",	"benign",	"benign",	"benign",
"benign",	"benign",	"benign",	"benign",	"benign",	"malignant",	"benign",
"benign",	"benign",	"benign",	"malignant",	"malignant",	"malignant")

breast_cancer_y <- as.factor(breast_cancer_y)


breast_cancer_x <- read_csv("~/R Scripts/breast_cancer_x.csv")

# Apply median imputation: model
model <- train(
  x = breast_cancer_x, y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = "medianImpute" 
)

# Print model to console
print(model)
```

##Use KNN imputation with breast cancer data set
```{r}
# Apply KNN imputation: model2
model2 <- train(
  x = breast_cancer_x, y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = "knnImpute"
)

# Print model to console
print(model2)
```

##Combining preprocessing methods
```{r}
# Fit glm with median imputation: model1
model1 <- train(
  x = breast_cancer_x, y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = "medianImpute"
)

# Print model1
print(model1)

# Fit glm with median imputation and standardization: model2
model2 <- train(
  x = breast_cancer_x, y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = c("medianImpute", "center", "scale")
)

# Print model2
print(model2)
```

##Remove near zero variance predictors
By default, caret uses freqCut = 19 and uniqueCut = 10, which is fairly conservative.
This model will run faster than using the full dataset and will yield very similar predictive accuracy.

Furthermore, zero variance variables can cause problems with cross-validation (e.g. if one fold ends up with only a single unique value for that variable), so removing them prior to modeling means you are less likely to get errors during the fitting process.
```{r}
bloodbrain_y <- c(1.08,	-0.4,	0.22,	0.14,	0.69,	0.44,	-0.43,	1.38,	0.75,	0.88,	0.98,	0.83,
0.61,	-1.17,	-0.67,	-0.66,	-0.12,	-0.73,	-0.27,	-0.28,	-0.24,	1.17,	1.38,	0.89,
-0.3,	0.88,	0.08,	-1.34,	0.39,	0.52,	0,	-1.82,	-0.79,	-0.62,	0.37,	0.82,
-0.23,	-1.89,	0.38,	0.16,	1.14,	0.1,	0.54,	0.87,	-1.3,	0.98,	-0.15,	0.96,
0.92,	0.41,	0.88,	0.63,	-0.48,	1.53,	0.46,	0.18,	-0.1,	-0.06,	-1.4,	-0.47,
-0.03,	-0.18,	0.34,	-1,	-0.42,	-0.89,	0.36,	0,	0.06,	0.11,	0.48,	1.26,
0.62,	0.85,	0.32,	-0.22,	-0.37,	0.74,	1.16,	-0.42,	-0.01,	0.48,	0.49,	0.53,
0,	0.06,	-0.89,	-0.05,	0.97,	0.59,	0.96,	1.64,	-0.31,	-1,	0.22,	0.47,
-0.23,	0.35,	0.36,	0.66,	0.16,	0.99,	-0.18,	0.6,	0.08,	-1.42,	0,	-0.72,
-0.48,	-0.01,	0.32,	-1.39,	0.3,	-0.34,	-0.79,	0.58,	0.41,	-0.65,	0.19,	0.33,
-1.4,	0.56,	-1.3,	-1.09,	0.04,	0.32,	-0.12,	-0.58,	0.07,	0.9,	0.89,	0.34,
0.84,	-0.78,	0.64,	0.23,	-1.42,	-0.83,	-0.16,	-0.3,	-0.22,	1.34,	-2.15,	1.15,
0.16,	0.67,	-1.26,	0.77,	0.56,	-0.3,	-0.17,	0.33,	0.4,	-0.3,	-0.04,	0,
-0.25,	-0.78,	-0.02,	0.04,	-0.29,	0.49,	0.38,	-0.87,	-0.2,	0.36,	-0.04,	-0.07,
-0.07,	0.55,	0.57,	-1.3,	-0.06,	0.39,	-0.28,	-1.23,	-0.55,	0.18,	0.41,	-1.1,
-0.82,	-1.3,	-2,	-1.15,	-1.54,	-1.57,	-1.12,	-0.72,	0.54,	0.2,	-0.18,	1.11,
-0.46,	-0.29,	1.6,	-0.3,	-2.15,	-1.06,	-0.09,	0.53,	1.03,	-2,	-0.22,	-0.02,
0.08,	0.25,	-0.84,	-0.25)

bloodbrain_x <- read_csv("~/R Scripts/bloodbrain_x.csv", 
    col_types = cols(adistd = col_number(), 
        adistm = col_number(), andrewbind = col_number(), 
        clogp = col_number(), dipole_moment = col_number(), 
        fpsa1 = col_number(), fpsa2 = col_number(), 
        frac.anion7. = col_number(), frac.cation7. = col_number(), 
        hardness = col_number(), homo = col_number(), 
        logp.o.w. = col_number(), lumo = col_number(), 
        mlogp = col_number(), most_negative_charge = col_number(), 
        most_positive_charge = col_number(), 
        mw = col_number(), nonpolar_area = col_number(), 
        ovality = col_number(), peoe_vsa.0 = col_number(), 
        peoe_vsa.0.1 = col_number(), peoe_vsa.1 = col_number(), 
        peoe_vsa.1.1 = col_number(), peoe_vsa.2 = col_number(), 
        peoe_vsa.2.1 = col_number(), peoe_vsa.3 = col_number(), 
        peoe_vsa.3.1 = col_number(), peoe_vsa.4 = col_number(), 
        peoe_vsa.4.1 = col_number(), peoe_vsa.5 = col_number(), 
        peoe_vsa.5.1 = col_number(), peoe_vsa.6 = col_number(), 
        peoe_vsa.6.1 = col_number(), pnsa1 = col_number(), 
        pnsa2 = col_number(), pnsa3 = col_number(), 
        polar_area = col_number(), ppsa1 = col_number(), 
        ppsa2 = col_number(), ppsa3 = col_number(), 
        psa_npsa = col_number(), slogp_vsa0 = col_number(), 
        slogp_vsa1 = col_number(), slogp_vsa2 = col_number(), 
        slogp_vsa3 = col_number(), slogp_vsa4 = col_number(), 
        slogp_vsa5 = col_number(), slogp_vsa6 = col_number(), 
        slogp_vsa7 = col_number(), slogp_vsa8 = col_number(), 
        slogp_vsa9 = col_number(), smr_vsa0 = col_number(), 
        smr_vsa1 = col_number(), smr_vsa2 = col_number(), 
        smr_vsa3 = col_number(), smr_vsa4 = col_number(), 
        smr_vsa5 = col_number(), smr_vsa6 = col_number(), 
        smr_vsa7 = col_number(), sum_absolute_charge = col_number(), 
        surface_area = col_number(), tcnp = col_number(), 
        tcpa = col_number(), tcsa = col_number(), 
        tpsa = col_number(), tpsa.1 = col_number(), 
        ub = col_number(), volume = col_number(), 
        vsa_acc = col_number(), vsa_base = col_number(), 
        vsa_don = col_number(), vsa_hyd = col_number(), 
        vsa_other = col_number(), vsa_pol = col_number(), 
        weight = col_number()))

# Identify near zero variance predictors: remove_cols
remove_cols <- nearZeroVar(bloodbrain_x, names = TRUE, 
                           freqCut = 2, uniqueCut = 20)

# Get all column names from bloodbrain_x: all_cols
all_cols <- names(bloodbrain_x)

# Remove from data: bloodbrain_x_small
bloodbrain_x_small <- bloodbrain_x[ , setdiff(all_cols, remove_cols)]

```

##Fit model on reduced blood-brain data
```{r}
# Fit model on reduced data: model
model <- train(x = bloodbrain_x_small, y = bloodbrain_y, method = "glm")

# Print model to console
print(model)
```
##Using PCA as an alternative to nearZeroVar()
```{r}
# Fit glm model using PCA: model
model <- train(
  x = bloodbrain_x, y = bloodbrain_y,
  method = "glm", preProcess = "pca"
)

# Print model to console
print(model)
```

Note that the PCA model's accuracy is slightly higher than the nearZeroVar() model from the previous exercise. PCA is generally a better method for handling low-information predictors than throwing them out entirely.

##Combo
```{r}
# Fit glm model using PCA: model
model <- train(
  x = bloodbrain_x, y = bloodbrain_y, method = "glm",
  trControl = trainControl(method="cv", number=10, verbose=TRUE),
  preProcess = c("zv", "center", "scale", "pca")
)

# Print model to console
print(model)

min(model$results$RMSE)
```

##Churn Case

#Make custom train/test indices
```{r}
churn_y <- c("no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"yes",	"no",	"no",	"no",	"no",
"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"yes",	"no",	"no",	"no",	"yes",
"no",	"yes",	"no",	"yes",	"no",	"yes",	"no",	"yes",	"yes",	"yes",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",
"no",	"yes",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"yes",	"no",	"yes",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",
"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"yes",	"no",	"no",	"no",	"no",
"no",	"no",	"no",	"yes",	"no",	"no",	"yes",	"yes",	"no",	"no",	"no",	"no",	"yes",	"no",	"yes",	"no",	"no",	"no",
"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no",	"no")

# Create custom indices: myFolds
myFolds <- createFolds(churn_y, k = 5) #create 5 CV fold

# Create reusable trainControl object: myControl
myControl <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = TRUE,
  savePredictions = TRUE,
  index = myFolds
)
```

##Fit the baseline model
```{r}


churn_x <- read_csv("~/R Scripts/churn_x.csv")
rownames(churn_x) <- churn_x$X1
churn_x$X1 <- NULL
View(churn_x)

# Fit glmnet model: model_glmnet
model_glmnet <- train(
  x = churn_x, y = churn_y,
  metric = "ROC",
  method = "glmnet",
  trControl = myControl
)

plot(model_glmnet)
plot(model_glmnet$finalModel)

```
##Random forest with custom trainControl
```{r}
# Fit random forest: model_rf
model_rf <- train(
  x = churn_x, y = churn_y,
  metric = "ROC",
  method = "ranger",
  trControl = myControl
)
plot(model_rf)
```
##Create a resamples object
```{r}
# Create model_list
model_list <- list(item1 = model_glmnet, item2 = model_rf)

# Pass model_list to resamples(): resamples
resamples <- resamples(model_list)

# Summarize the results
summary(resamples)
```
##Create a box-and-whisker plot
In general, you want the model with the higher median AUC, as well as a smaller range between min and max AUC.
```{r}
# Create bwplot
bwplot(resamples) #,metric="ROC"
```
##Create a scatterplot
This plot shows you how similar the two models' performances are on different folds.

It's particularly useful for identifying if one model is consistently better than the other across all folds, or if there are situations when the inferior model produces better predictions on a particular subset of the data.
```{r}
# Create xyplot
xyplot(resamples, metric="ROC")
```
##Ensembling models
```{r}
caretList <- function (..., trControl = NULL, methodList = NULL, tuneList = NULL, 
    continue_on_fail = FALSE) 
{
    if (is.null(trControl)) {
        trControl <- trainControl()
    }
    if (is.null(tuneList) & is.null(methodList)) {
        stop("Please either define a methodList or tuneList")
    }
    if (!is.null(methodList) & any(duplicated(methodList))) {
        warning("Duplicate entries in methodList.  Using unqiue methodList values.")
        methodList <- unique(methodList)
    }
    if (!is.null(methodList)) {
        methodCheck(methodList)
        tuneList_extra <- lapply(methodList, caretModelSpec)
        tuneList <- c(tuneList, tuneList_extra)
    }
    tuneList <- tuneCheck(tuneList)
    global_args <- list(...)
    if (is.null(trControl$index)) {
        target <- extractCaretTarget(...)
        trControl <- trControlCheck(x = trControl, y = target)
    }
    global_args[["trControl"]] <- trControl
    modelList <- lapply(tuneList, function(m) {
        model_args <- c(global_args, m)
        if (continue_on_fail == TRUE) {
            model <- tryCatch(do.call(train, model_args), error = function(e) NULL)
        }
        else {
            model <- do.call(train, model_args)
        }
        return(model)
    })
    names(modelList) <- names(tuneList)
    nulls <- sapply(modelList, is.null)
    modelList <- modelList[!nulls]
    if (length(modelList) == 0) {
        stop("caret:train failed for all models.  Please inspect your data.")
    }
    class(modelList) <- "caretList"
    return(modelList)
}

# Create ensemble model: stack
stack <- caretStack(model_list, method = "glm")

# Look at summary
summary(stack)
```
